<!DOCTYPE html>

<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style></style>

  <meta name="description" content="DeepGen">
  <meta name="keywords" content="Text-to-image Generation,Semantic Evaluation, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DeepGen</title>


  <link rel="shortcut icon" href="https://picx.zhimg.com/v2-cb40b1f8c3125f3cfb9a4538e1c0f2b7_l.jpg?source=32738c0c" type="image/x-icon">
  <link href="./static/css" rel="stylesheet">

  <link rel="stylesheet" href="./static/bulma.min.css">
  <link rel="stylesheet" href="./static/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/academicons.min.css">
  <link rel="stylesheet" href="./static/index.css">
  <link rel="stylesheet" href="./static/leaderboard.css">

  <script type="text/javascript" src="./static/sort-table.js" defer=""></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer="" src="./static/fontawesome.all.min.js"></script>
  <script src="./static/bulma-carousel.min.js"></script>
  <script src="./static/bulma-slider.min.js"></script>
  <script src="./static/explorer-index.js"></script>
  <script src="./static/question_card.js"></script>

  <script src="./static/ard_testmini.js"></script>
  <script src="./static/output_folders.js" defer=""></script>
  <script src="./static/model_scores.js" defer=""></script>

  <script src="./static/data_public.js" defer=""></script>

  <style>
      .center-container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100%;
            margin-top: -20px;
        }
    .node {
      fill: #f8f1e4;
      stroke: #000;
      stroke-width: 1;
      rx: 10;
      ry: 10;
    }
    .node text {
      font-size: 14px;
      text-anchor: middle;
    }
    .link {
      fill: none;
      stroke: #000;
      stroke-width: 2;
    }
    .badge {
      font-size: 12px;
    }
  </style>

</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold" style="display: inline-block; margin-right: 0px;">
            <span style="vertical-align: middle">DeepGen 1.0: A Lightweight Unified Multimodal
Model for Advancing Image Generation and Editing</span>
            </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=iP2HPFEAAAAJ"><b>Dianyi Wang</b></a><sup>1,2*â€ </sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=BuRGJswAAAAJ"><b>Ruihang Li</b></a><sup>1,3*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=oFmRTTkAAAAJ&hl=zh-CN"><b>Feng Han</b></a><sup>1,2*</sup>,</span>
            <span class="author-block"><a href=""><b>Chaofan Ma</b></a><sup>4*</sup>,</span>
            <span class="author-block"><a href=""><b>Wei Song</b></a><sup>1,5,6*</sup>,</span>
            <span class="author-block"><a href=""><b>Siyuan Wang</b></a><sup>8*</sup>,</span>
            <br>
            <span class="author-block"><a href="https://codegoat24.github.io/"><b>Yibin Wang</b></a><sup>1,2*</sup>,</span>
            <span class="author-block"><a href=""><b>Yi Xin</b></a><sup>1,7</sup>,</span>
            <span class="author-block"><a href=""><b>Hongjian Liu</b></a><sup>3</sup>,</span>
            <span class="author-block"><a href=""><b>Zhixiong Zhang</b></a><sup>1,4</sup>,</span>
            <span class="author-block"><a href=""><b>Shengyuan Ding</b></a><sup>1,2</sup>,</span>
            <span class="author-block"><a href=""><b>Tianhang Wang</b></a><sup>1,5</sup>,</span>
            <span class="author-block"><a href=""><b>Zhenglin Cheng</b></a><sup>1,5,6</sup>,</span>
            <span class="author-block"><a href=""><b>Tao Lin</b></a><sup>6</sup>,</span>
            <br>
            <span class="author-block"><a href=""><b>Cheng Jin</b></a><sup>2</sup>,</span>
            <span class="author-block"><a href=""><b>Kaicheng Yu</b></a><sup>6</sup>,</span>
            <span class="author-block"><a href="https://jingjing1.github.io/#teach"><b>Jingjing Chen</b></a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=Ma5DtmoAAAAJ"><b>Wenjie Wang</b></a><sup>3</sup>,</span>
            <span class="author-block"><a href=""><b>Zhongyu Wei</b></a><sup>1,2</sup>,</span>
            <span class="author-block"><a href="https://myownskyw7.github.io/"><b>Jiaqi Wang</b></a><sup>1â€ </sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block" style="margin-right: 15px;"><sup>1</sup>Shanghai Innovation Institute,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>2</sup>Fudan University,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>3</sup>University of Science and Technology of China,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>4</sup>Shanghai Jiao Tong University,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>5</sup>Zhejiang University,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>6</sup>Westlake University,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>7</sup>Nanjing University,</span>
            <span class="author-block" style="margin-right: 15px;"><sup>8</sup>University of Southern California</span>
          </div>
          <div class="is-size-6 has-text-centered" style="margin-top: 6px;">
            <sup>*</sup> Core Contributors &nbsp;&nbsp; <sup>â€ </sup> Project Leaders
          </div>
          <!-- ArXiv Link. -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="http://arxiv.org/abs/2602.12205" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->

              <span class="link-block">
                <a href="https://huggingface.co/DeepGenTeam/DeepGen-1.0" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ˜Š
                  </span>
                  <span>DeepGen</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/deepgenteam/deepgen" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/deepgenteam/deepgen_SFT" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ˜Š
                  </span>
                  <span>DeepGen-data</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Begin Teaser -->
<div>
<section class="section">
  <div class="container is-max-desktop" >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h1 class="title is-3">DeepGen Overview</h1>

      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content has-text-centered" style="margin-top: 1cm;">
          <img src="./static/images/demonstrate.png" alt="data-overview" style="max-width: 100%; height: auto;">
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content has-text-centered" style="margin-top: 1cm;">
          <img src="./static/images/method.png" alt="data-overview" style="max-width: 100%; height: auto;">
        </div>
      </div>
    </div>
    <div class="hero-body">
      <h2 class="subtitle has-text-justified">
        <p class="has-text-centered"><b>Method Overview.</b><br>DeepGen 1.0 adopts a unified VLMâ€“DiT framework with dual-branch visual encoding: a ViT provides semantic features, while a VAE extracts latent representations for the DiT. Multimodal VLM conditions and reference-image VAE latents are concatenated with target noise tokens as a single DiT sequence, enabling joint self-attention over conditioning and generation. Stacked Channel Bridging (SCB) fuses VLM and DiT features, and positional encodings distinguish reference from target tokens. Icons denote frozen/trainable modules across pre-training, SFT, and RL.</p>
      </h2>
    </div>

  </div>
  </div>

  </section>
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="content has-text-centered">
        <img src="static/images/training_data.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered"><b>Training Data and Evaluation Overview.</b><br>Overview of our training data for broad omni-capabilities and comprehensive evaluation across benchmarks.</p>
        </h2>
      </div>
      <div class="content has-text-centered">
        <img src="static/images/performance_comparison.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered">This figure presents a comparison on image generation and editing benchmarks. Bubble size is proportional
to model parameter count. Dashed outer rings indicate models with unreported parameter counts. Higher scores
correspond to better performance.</p>
        </h2>
      </div>
    </div>
  </section>
</div>



</section>
  <section class="hero teaser">
    <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Quantitative Results</h2>

      </div>
    </div>
      <div class="content has-text-centered">
        <img src="static/images/benchmark1.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered">This figure presents quantitative results across general image generation and editing benchmarks. Top-1/2/3 results
within each column excluding closed-source models are marked with gold, silver, and bronze icons.</p>
        </h2>
      </div>

      <div class="content has-text-centered">
        <img src="static/images/benchmark_wise.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered">This figure presents quantitative results of reasoning-based text-to-image generation involving world knowledge on the WISE benchmark.
"*" denotes generation with textual CoT reasoning.</p>
        </h2>
      </div>

      <div class="content has-text-centered">
        <img src="static/images/benchmark_corebench.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered">This figure presents quantitative results of reasoning-based text-to-image generation with the philosophical framework on the T2I-
CoREBench benchmark through Qwen3-VL-32B-Thinking. "*" denotes generation with textual CoT reasoning.</p>
        </h2>
      </div>

      <div class="content has-text-centered">
        <img src="static/images/benchmark_rise_uniredit.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered">This figure presents quantitative results of reasoning-based editing involving world knowledge on the RISE and UniREditBench. "*"
denotes generation with textual CoT reasoning.</p>
        </h2>
      </div>
      <div class="content has-text-centered">
        <img src="static/images/benchmark_cvtg.png" alt="data-overview" width="1200" height="800">
      </div>
      <div class="hero-body">
        <h2 class="subtitle has-text-justified">
          <p class="has-text-centered">This figure presents quantitative results of text rendering on the CVTG-2K.</p>
        </h2>
      </div>

    </div>
  </section>
</div>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code class="language-bibtex"></code></pre>
  </div>
</section>









</body></html>
